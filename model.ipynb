{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guidance on using this dataset: https://www.kaggle.com/code/acelevin/identifying-playing-cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset from: https://www.kaggle.com/datasets/gunhcolab/object-detection-dataset-standard-52card-deck/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters:\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [filename, width, height, class, xmin, ymin, xmax, ymax, class_number]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [filename, width, height, class, xmin, ymin, xmax, ymax, class_number]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Load in data\n",
    "train_labels = pd.read_csv(\"data/train_labels.csv\")\n",
    "test_labels = pd.read_csv(\"data/test_labels.csv\")\n",
    "\n",
    "# change class labels from str to int\n",
    "name_to_int_dict = {'ace of spades': 0, 'two of spades':1, 'three of spades':2, 'four of spades':3, \n",
    "                    'five of spades':4, 'six of spades':5, 'seven of spades':6, 'eight of spades':7, \n",
    "                    'nine of spades':8, 'ten of spades':9, 'jack of spades':10, 'queen of spades':11, \n",
    "                    'king of spades':12, 'ace of hearts': 13, 'two of hearts': 14, 'three of hearts': 15, \n",
    "                    'four of hearts': 16, 'five of hearts': 17, 'six of hearts': 18, 'seven of hearts':19, \n",
    "                    'eight of hearts':20, 'nine of hearts':21, 'ten of hearts':22, 'jack of hearts': 23, \n",
    "                    'queen of hearts': 24, 'king of hearts':25, 'ace of clubs': 26, 'two of clubs': 27, \n",
    "                    'three of clubs': 28, 'four of clubs': 29, 'five of clubs': 30, 'six of clubs': 31,\n",
    "                    'seven of clubs':32, 'eight of clubs':33, 'nine of clubs':34, 'ten of clubs':35, \n",
    "                    'jack of clubs': 36, 'queen of clubs': 37, 'king of clubs':38, 'ace of diamonds': 39, \n",
    "                    'two of diamonds': 40, 'three of diamonds': 41, 'four of diamonds': 42, 'five of diamonds': 43, \n",
    "                    'six of diamonds': 44,'seven of diamonds':45, 'eight of diamonds':46, 'nine of diamonds':47, \n",
    "                    'ten of diamonds':48, 'jack of diamonds': 49, 'queen of diamonds': 50,'king of diamonds':51,\n",
    "                    \n",
    "                    # these are to account for some typos in the dataset\n",
    "                    'three of dimaonds': 41, 'four of dimaonds': 42, 'five of dimaonds': 43, 'six of dimaonds': 44, \n",
    "                    'eigth of clubs':33, 'seven of seven':32 \n",
    "                    }\n",
    "\n",
    "test_labels['class_number'] = test_labels['class'].map(name_to_int_dict)\n",
    "train_labels['class_number'] = train_labels['class'].map(name_to_int_dict)\n",
    "\n",
    "# These should print empty to show that all labels are accounted for\n",
    "print(test_labels.loc[test_labels['class_number'].isnull()])\n",
    "print(train_labels.loc[train_labels['class_number'].isnull()])\n",
    "\n",
    "image_paths_train = train_labels['filename'].values\n",
    "labels_train = train_labels['class_number'].values\n",
    "\n",
    "image_paths_test = test_labels['filename'].values\n",
    "labels_test = test_labels['class_number'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(539, 539, 98, 98)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((image_paths_train, labels_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((image_paths_test, labels_test))\n",
    "\n",
    "def load_train_image(image_path, label):\n",
    "    image_path = tf.strings.join(['train/', image_path], separator='')\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "def load_test_image(image_path, label):\n",
    "    image_path = tf.strings.join(['test/', image_path], separator='')\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(load_train_image, num_parallel_calls=tf.data.AUTOTUNE).shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(load_test_image, num_parallel_calls=tf.data.AUTOTUNE).shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardPredictor(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CardPredictor, self).__init__()\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "        \n",
    "        self.architecture = [              \n",
    "              tf.keras.layers.Conv2D(100, (5, 5), strides=(2,2)),\n",
    "              tf.keras.layers.BatchNormalization(),\n",
    "              tf.keras.layers.ReLU(),\n",
    "              tf.keras.layers.Dropout(0.4),\n",
    "              tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "              \n",
    "              tf.keras.layers.Conv2D(250, (4, 4), strides=(1,1)),\n",
    "              tf.keras.layers.BatchNormalization(),\n",
    "              tf.keras.layers.ReLU(),\n",
    "              tf.keras.layers.Dropout(0.4),\n",
    "              tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "              \n",
    "              tf.keras.layers.Conv2D(450, (3, 3), strides=(1,1)),\n",
    "              tf.keras.layers.BatchNormalization(),\n",
    "              tf.keras.layers.ReLU(),\n",
    "              tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1)),\n",
    "              \n",
    "              tf.keras.layers.Conv2D(650, (3, 3), strides=(1,1)),\n",
    "              tf.keras.layers.BatchNormalization(),\n",
    "              tf.keras.layers.ReLU(),\n",
    "              tf.keras.layers.Conv2D(650, (3, 3), strides=(1,1)),\n",
    "              tf.keras.layers.BatchNormalization(),\n",
    "              tf.keras.layers.ReLU(),\n",
    "              tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1)),\n",
    "              \n",
    "              #Flatten\n",
    "              tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1)),\n",
    "              \n",
    "              tf.keras.layers.Dense(300),\n",
    "              tf.keras.layers.BatchNormalization(),\n",
    "              tf.keras.layers.ReLU(),\n",
    "              tf.keras.layers.Dropout(0.6),\n",
    "              \n",
    "              tf.keras.layers.Dense(300),\n",
    "              tf.keras.layers.BatchNormalization(),\n",
    "              tf.keras.layers.ReLU(),\n",
    "              tf.keras.layers.Dropout(0.6),\n",
    "              \n",
    "              tf.keras.layers.Dense(200),\n",
    "              tf.keras.layers.BatchNormalization(),\n",
    "              tf.keras.layers.ReLU(),\n",
    "              tf.keras.layers.Dropout(0.6),\n",
    "              \n",
    "              tf.keras.layers.Dense(15, activation='softmax')]\n",
    "        \n",
    "        self.sequential = tf.keras.Sequential(self.architecture, name=\"card_predictor\")\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\" Passes input image through the network. \"\"\"\n",
    "        return self.sequential(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_fn(labels, predictions): \n",
    "           \"\"\" Loss function for the model. \"\"\"\n",
    "           return tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 384ms/step - accuracy: 0.0264 - loss: 0.7984 - val_accuracy: 0.0204 - val_loss: 1.0335\n",
      "Epoch 2/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 349ms/step - accuracy: 0.0121 - loss: 1.2360 - val_accuracy: 0.0102 - val_loss: 9.9040\n",
      "Epoch 3/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 372ms/step - accuracy: 0.0170 - loss: 29.7570 - val_accuracy: 0.0204 - val_loss: 188.5230\n",
      "Epoch 4/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 377ms/step - accuracy: 0.0160 - loss: 404.9336 - val_accuracy: 0.0102 - val_loss: 1231.3318\n",
      "Epoch 5/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - accuracy: 0.0096 - loss: 3525.3657 - val_accuracy: 0.0204 - val_loss: 12701.6865\n",
      "Epoch 6/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 396ms/step - accuracy: 0.0148 - loss: 19718.2598 - val_accuracy: 0.0102 - val_loss: 79958.2188\n",
      "Epoch 7/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 384ms/step - accuracy: 0.0153 - loss: 91445.2422 - val_accuracy: 0.0306 - val_loss: 300491.5625\n",
      "Epoch 8/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 376ms/step - accuracy: 0.0151 - loss: 414598.0000 - val_accuracy: 0.0306 - val_loss: 1134419.8750\n",
      "Epoch 9/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 384ms/step - accuracy: 0.0307 - loss: 1468362.5000 - val_accuracy: 0.0102 - val_loss: 4057415.2500\n",
      "Epoch 10/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 376ms/step - accuracy: 0.0205 - loss: 4570144.0000 - val_accuracy: 0.0102 - val_loss: 12172652.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 376ms/step - accuracy: 0.0147 - loss: 17442452.0000 - val_accuracy: 0.0102 - val_loss: 30093028.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m 9/17\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 346ms/step - accuracy: 0.0116 - loss: 32109922.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m CardPredictor()\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mloss_fn, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cs1430/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/cs1430/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniforge3/envs/cs1430/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m ):\n\u001b[1;32m    219\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/miniforge3/envs/cs1430/lib/python3.9/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cs1430/lib/python3.9/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptionalHasValue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CardPredictor()\n",
    "model.compile(optimizer=model.optimizer, loss=model.loss_fn, metrics=['accuracy'])\n",
    "model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs1430",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
