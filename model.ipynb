{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guidance on using this dataset: https://www.kaggle.com/code/acelevin/identifying-playing-cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset from: https://www.kaggle.com/datasets/gunhcolab/object-detection-dataset-standard-52card-deck/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters:\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardPredictor(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CardPredictor, self).__init__()\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "        \n",
    "        data_augmentation = tf.keras.models.Sequential([\n",
    "                                tf.keras.layers.RandomRotation(0.1),\n",
    "                                tf.keras.layers.RandomZoom(0.1),\n",
    "                            ])\n",
    "        \n",
    "        self.architecture = [        \n",
    "                tf.keras.layers.InputLayer((300, 300, 3)),\n",
    "                data_augmentation,\n",
    "                \n",
    "                tf.keras.layers.Conv2D(32, 3, padding='same', use_bias=False),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.ReLU(),\n",
    "                tf.keras.layers.Conv2D(32, 3, padding='same', use_bias=False),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.ReLU(),\n",
    "                \n",
    "                tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                tf.keras.layers.Dropout(0.2),\n",
    "                \n",
    "                tf.keras.layers.Conv2D(64, 3, padding='same', use_bias=False),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.ReLU(),\n",
    "                tf.keras.layers.Conv2D(64, 3, padding='same', use_bias=False),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.ReLU(),\n",
    "                \n",
    "                tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                tf.keras.layers.Dropout(0.3),\n",
    "                \n",
    "                tf.keras.layers.Conv2D(128, 3, padding='same', use_bias=False),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.ReLU(),\n",
    "                tf.keras.layers.Conv2D(128, 3, padding='same', use_bias=False),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.ReLU(),\n",
    "                \n",
    "                tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                tf.keras.layers.Dropout(0.4),\n",
    "                \n",
    "                tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                \n",
    "                tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "                tf.keras.layers.Dropout(0.5),\n",
    "                tf.keras.layers.Dense(52, activation='softmax')        \n",
    "                ]\n",
    "        \n",
    "        self.sequential = tf.keras.Sequential(self.architecture, name=\"card_predictor\")\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\" Passes input image through the network. \"\"\"\n",
    "        return self.sequential(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_fn(labels, predictions): \n",
    "           \"\"\" Loss function for the model. \"\"\"\n",
    "           return tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "new_data = {}\n",
    "for key, inner_dict in data.items():\n",
    "    img_path = inner_dict['img_path']\n",
    "    value = inner_dict['class_label']\n",
    "    new_data[img_path] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:21:47.424682: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-04-29 21:21:47.424721: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-04-29 21:21:47.424726: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-04-29 21:21:47.424753: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-29 21:21:47.424771: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((new_data.keys(), new_data.values()))\n",
    "\n",
    "def load_train_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [300, 300])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(load_train_image, num_parallel_calls=tf.data.AUTOTUNE).shuffle(buffer_size=10000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:21:48.904347: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: imgs/single/5.png; No such file or directory\n",
      "2025-04-29 21:21:48.904360: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: imgs/single/0.png; No such file or directory\n",
      "2025-04-29 21:21:48.904369: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: imgs/single/2.png; No such file or directory\n",
      "2025-04-29 21:21:48.904378: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: imgs/single/1.png; No such file or directory\n",
      "2025-04-29 21:21:48.904442: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: imgs/single/9.png; No such file or directory\n",
      "2025-04-29 21:21:48.904456: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: imgs/single/3.png; No such file or directory\n",
      "2025-04-29 21:21:48.904461: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: NOT_FOUND: Error in user-defined function passed to ParallelMapDatasetV2:1 transformation with iterator: Iterator::Root::Prefetch::FiniteSkip::Prefetch::BatchV2::Shuffle::ParallelMapV2: imgs/single/0.png; No such file or directory\n",
      "\t [[{{node ReadFile}}]]\n",
      "2025-04-29 21:21:48.904468: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: imgs/single/7.png; No such file or directory\n",
      "2025-04-29 21:21:48.904479: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: imgs/single/6.png; No such file or directory\n",
      "2025-04-29 21:21:48.904491: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: imgs/single/4.png; No such file or directory\n",
      "2025-04-29 21:21:48.904509: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: imgs/single/8.png; No such file or directory\n",
      "2025-04-29 21:21:48.904534: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: imgs/single/10.png; No such file or directory\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to ParallelMapDatasetV2:1 transformation with iterator: Iterator::Root::Prefetch::FiniteSkip::Prefetch::BatchV2::Shuffle::ParallelMapV2: imgs/single/0.png; No such file or directory\n\t [[{{node ReadFile}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m v_counts \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mCounter()\n\u001b[1;32m      5\u001b[0m t_counts \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mCounter()\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, label \u001b[38;5;129;01min\u001b[39;00m val_dataset:\n\u001b[1;32m      8\u001b[0m     label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist() \n\u001b[1;32m      9\u001b[0m     v_counts\u001b[38;5;241m.\u001b[39mupdate(label)\n",
      "File \u001b[0;32m~/miniforge3/envs/csci1430/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/csci1430/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/csci1430/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/csci1430/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error in user-defined function passed to ParallelMapDatasetV2:1 transformation with iterator: Iterator::Root::Prefetch::FiniteSkip::Prefetch::BatchV2::Shuffle::ParallelMapV2: imgs/single/0.png; No such file or directory\n\t [[{{node ReadFile}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "# this cell it optional\n",
    "# this checks that the dataset is balanced\n",
    "import collections\n",
    "v_counts = collections.Counter()\n",
    "t_counts = collections.Counter()\n",
    "\n",
    "for _, label in val_dataset:\n",
    "    label = label.numpy().tolist() \n",
    "    v_counts.update(label)\n",
    "\n",
    "for _, label in train_dataset:\n",
    "    label = label.numpy().tolist() \n",
    "    t_counts.update(label)\n",
    "    \n",
    "print(\"Label counts in validation dataset:\")\n",
    "for i in range(52):\n",
    "    print(f\"Label {i}: {v_counts[i]}, {t_counts[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:34:29.527960: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-04-29 21:34:29.527991: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-04-29 21:34:29.527995: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-04-29 21:34:29.528012: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-29 21:34:29.528025: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = CardPredictor()\n",
    "#model = tf.keras.models.load_model(\"MODEL_PATH\")\n",
    "\n",
    "model.compile(optimizer=model.optimizer, loss=model.loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrain_dataset\u001b[49m, \n\u001b[1;32m      2\u001b[0m           validation_data\u001b[38;5;241m=\u001b[39mval_dataset, \n\u001b[1;32m      3\u001b[0m           epochs\u001b[38;5;241m=\u001b[39mNUM_EPOCHS, \n\u001b[1;32m      4\u001b[0m           verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, \n",
    "          validation_data=val_dataset, \n",
    "          epochs=NUM_EPOCHS, \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are saving a model that has not yet been built. Try building the model first by calling it on some data or by using `build()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_weights.weights.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/csci1430/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/csci1430/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:519\u001b[0m, in \u001b[0;36msave_weights_only\u001b[0;34m(model, filepath, objects_to_skip)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Save only the weights of a model to a target filepath.\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;03mSupports both `.weights.h5` and `.keras`.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    520\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are saving a model that has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry building the model first by calling it on some data or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby using `build()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    523\u001b[0m     )\n\u001b[1;32m    525\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(filepath)\n\u001b[1;32m    526\u001b[0m tmp_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: You are saving a model that has not yet been built. Try building the model first by calling it on some data or by using `build()`."
     ]
    }
   ],
   "source": [
    "model.save_weights('model_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video capture and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassiraouf/miniforge3/envs/csci1430/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 46 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model = CardPredictor()\n",
    "model.build((None, 300, 300, 3))\n",
    "model.load_weights('model_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:34:38.881 python[10625:18927309] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'c' to capture and classify a card.\n",
      "Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:34:42.497 python[10625:18927309] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-29 21:34:42.497 python[10625:18927309] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Capturing frame...\n",
      "Exiting.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = CardPredictor()\n",
    "model.build((None, 300, 300, 3))\n",
    "model.load_weights('model_weights.weights.h5')\n",
    "\n",
    "values = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\n",
    "suits = ['spade', 'heart', 'diamond', 'club']\n",
    "class_names = [f\"{v} of {s}\" for v in values for s in suits]\n",
    "# === Start camera ===\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "if not cam.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Press 'c' to capture and classify a card.\")\n",
    "print(\"Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Show the camera feed\n",
    "    cv2.imshow(\"Live Feed - Press 'c' to classify, 'q' to quit\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q'):\n",
    "        print(\"Exiting.\")\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        print(\"Capturing frame...\")\n",
    "\n",
    "        # Preprocess the frame\n",
    "        img = cv2.resize(frame, (300, 300))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        # Predict\n",
    "        pred = model(img, training=False)\n",
    "        predicted_class = tf.argmax(pred, axis=1).numpy()[0]\n",
    "        # check dataset to fix the indexing here.\n",
    "        class_name = class_names[predicted_class]\n",
    "\n",
    "        # Overlay prediction and display result on the top right corner of the image. \n",
    "        display_frame = frame.copy()\n",
    "        cv2.putText(display_frame, f\"Prediction: {class_name}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Prediction\", display_frame)\n",
    "        cv2.waitKey(1500)  # Show prediction for 1.5 seconds\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs1430",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
